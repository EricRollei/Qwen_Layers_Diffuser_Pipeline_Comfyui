{
  "last_node_id": 16,
  "last_link_id": 22,
  "nodes": [
    {
      "id": 1,
      "type": "UNETLoader",
      "pos": [100, 100],
      "size": [280, 82],
      "properties": {},
      "widgets_values": ["Qwen-Edit/qwenImageLayered2512_bf16.safetensors", "fp8_e4m3fn"]
    },
    {
      "id": 2,
      "type": "EricQwenRGBAVAELoader",
      "pos": [100, 250],
      "size": [280, 82],
      "properties": {},
      "widgets_values": ["qwen_image_layered_vae.safetensors", 4, 4],
      "title": "Load RGBA VAE (4 channels)"
    },
    {
      "id": 3,
      "type": "CLIPLoader",
      "pos": [100, 370],
      "size": [280, 82],
      "properties": {},
      "widgets_values": ["qwen_2.5_vl_7b.safetensors", "qwen_image"]
    },
    {
      "id": 4,
      "type": "LoadImage",
      "pos": [100, 520],
      "size": [280, 314],
      "properties": {},
      "widgets_values": ["example.png", "image"]
    },
    {
      "id": 16,
      "type": "EricQwenAddAlpha",
      "pos": [450, 520],
      "size": [260, 80],
      "properties": {},
      "widgets_values": [1.0],
      "title": "Add Alpha Channel (RGBA)"
    },
    {
      "id": 5,
      "type": "ModelSamplingAuraFlow",
      "pos": [450, 100],
      "size": [260, 58],
      "properties": {},
      "widgets_values": [1.0]
    },
    {
      "id": 6,
      "type": "VAEEncode",
      "pos": [750, 520],
      "size": [200, 46],
      "properties": {}
    },
    {
      "id": 7,
      "type": "CLIPTextEncode",
      "pos": [450, 250],
      "size": [280, 100],
      "properties": {},
      "widgets_values": ["Decompose this image into 3 distinct layers with transparent backgrounds. Separate foreground subjects from background elements."]
    },
    {
      "id": 8,
      "type": "CLIPTextEncode",
      "pos": [450, 370],
      "size": [280, 100],
      "properties": {},
      "widgets_values": ["blurry, noisy, artifacts, merged layers"]
    },
    {
      "id": 9,
      "type": "ReferenceLatent",
      "pos": [1000, 250],
      "size": [250, 46],
      "properties": {}
    },
    {
      "id": 10,
      "type": "ReferenceLatent",
      "pos": [1000, 350],
      "size": [250, 46],
      "properties": {}
    },
    {
      "id": 11,
      "type": "EmptyHunyuanLatentVideo",
      "pos": [1000, 460],
      "size": [280, 130],
      "properties": {},
      "widgets_values": [1024, 1024, 13, 1]
    },
    {
      "id": 12,
      "type": "KSampler",
      "pos": [1350, 250],
      "size": [280, 262],
      "properties": {},
      "widgets_values": [123456, "randomize", 20, 3.5, "euler", "simple", 1.0]
    },
    {
      "id": 13,
      "type": "EricQwenLatentCutToBatch",
      "pos": [1700, 250],
      "size": [260, 58],
      "properties": {},
      "widgets_values": [false]
    },
    {
      "id": 14,
      "type": "VAEDecode",
      "pos": [1700, 380],
      "size": [200, 46],
      "properties": {}
    },
    {
      "id": 15,
      "type": "SaveImage",
      "pos": [1700, 500],
      "size": [280, 270],
      "properties": {},
      "widgets_values": ["qwen_layers/layer"]
    }
  ],
  "links": [
    [1, 1, 0, 5, 0, "MODEL"],
    [2, 5, 0, 12, 0, "MODEL"],
    [3, 2, 0, 6, 1, "VAE"],
    [4, 4, 0, 16, 0, "IMAGE"],
    [20, 16, 0, 6, 0, "IMAGE"],
    [5, 3, 0, 7, 0, "CLIP"],
    [6, 3, 0, 8, 0, "CLIP"],
    [7, 7, 0, 9, 0, "CONDITIONING"],
    [8, 6, 0, 9, 1, "LATENT"],
    [9, 8, 0, 10, 0, "CONDITIONING"],
    [10, 6, 0, 10, 1, "LATENT"],
    [11, 9, 0, 12, 1, "CONDITIONING"],
    [12, 10, 0, 12, 2, "CONDITIONING"],
    [13, 11, 0, 12, 3, "LATENT"],
    [14, 12, 0, 13, 0, "LATENT"],
    [15, 13, 0, 14, 0, "LATENT"],
    [16, 2, 0, 14, 1, "VAE"],
    [17, 14, 0, 15, 0, "IMAGE"]
  ],
  "groups": [],
  "config": {},
  "extra": {
    "ds": {
      "scale": 0.7,
      "offset": [0, 0]
    },
    "info": {
      "name": "Qwen-Image-Layered Native Workflow",
      "author": "Eric Hiss (EricRollei)",
      "description": "Native ComfyUI workflow for Qwen-Image-Layered layer decomposition",
      "notes": [
        "CRITICAL: LoadImage outputs RGB, but Qwen Layered VAE requires RGBA",
        "Use EricQwenAddAlpha between LoadImage and VAEEncode",
        "EmptyHunyuanLatentVideo length formula: (layers * 4) + 1",
        "length=13 for 3 layers, length=17 for 4 layers",
        "ModelSamplingAuraFlow shift=1 is required for this model"
      ]
    }
  },
  "version": 0.4
}
